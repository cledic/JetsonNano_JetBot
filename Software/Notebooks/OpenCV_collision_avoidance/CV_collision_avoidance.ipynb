{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La Cam da OpenCV deve essere usate tramite GStreamer con un comando dedicato\n",
    "# https://stackoverflow.com/questions/64272731/open-cv-shows-green-screen-on-jetson-nano\n",
    "#\n",
    "# Eseguire :\n",
    "# sudo nvpmodel -m 0\n",
    "# sudo jetson_clocks\n",
    "# per portare a 4 le CPU operative. OpenCV su NVIDIA Jetson Nano non Ã¨ ottimizzato per usare la GPU\n",
    "# Il codice gira tutto su CPU con una certa lentezza.\n",
    "#\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output, display, Image\n",
    "import ipywidgets\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_chunks function creats chunks.\n",
    "# inputs -- EdgeArray and the size_of_chunk to create.\n",
    "# output -- yield successive n-sized chunks.\n",
    "def make_chunks(EdgeArray, size_of_chunk):\n",
    "    chunks = []\n",
    "    for i in range(0, len(EdgeArray), size_of_chunk):\n",
    "        chunks.append(EdgeArray[i:i + size_of_chunk])\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# https://github.com/JetsonHacksNano/CSI-Camera/blob/master/simple_camera.py\n",
    "#\n",
    "\n",
    "# MIT License\n",
    "# Copyright (c) 2019-2022 JetsonHacks\n",
    "\n",
    "# Using a CSI camera (such as the Raspberry Pi Version 2) connected to a\n",
    "# NVIDIA Jetson Nano Developer Kit using OpenCV\n",
    "# Drivers for the camera and OpenCV are included in the base image\n",
    "\n",
    "import cv2\n",
    "\n",
    "\"\"\" \n",
    "gstreamer_pipeline returns a GStreamer pipeline for capturing from the CSI camera\n",
    "Flip the image by setting the flip_method (most common values: 0 and 2)\n",
    "display_width and display_height determine the size of each camera pane in the window on the screen\n",
    "Default 1920x1080 displayd in a 1/4 size window\n",
    "\"\"\"\n",
    "\n",
    "def gstreamer_pipeline(\n",
    "    sensor_id=0,\n",
    "    capture_width=640,\n",
    "    capture_height=480,\n",
    "    display_width=640,\n",
    "    display_height=480,\n",
    "    framerate=20,\n",
    "    flip_method=0,\n",
    "):\n",
    "    return (\n",
    "        \"nvarguscamerasrc sensor-id=%d !\"\n",
    "        \"video/x-raw(memory:NVMM), width=(int)%d, height=(int)%d, framerate=(fraction)%d/1 ! \"\n",
    "        \"nvvidconv flip-method=%d ! \"\n",
    "        \"video/x-raw, width=(int)%d, height=(int)%d, format=(string)BGRx ! \"\n",
    "        \"videoconvert ! \"\n",
    "        \"video/x-raw, format=(string)BGR ! appsink\"\n",
    "        % (\n",
    "            sensor_id,\n",
    "            capture_width,\n",
    "            capture_height,\n",
    "            framerate,\n",
    "            flip_method,\n",
    "            display_width,\n",
    "            display_height,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# To display images to verify. Set to zero if not intrested in displaying images.\n",
    "testmode = 1  \n",
    "\n",
    "# Code to draw edge representation.\n",
    "\n",
    "# cap = cv2.VideoCapture(0)  # Creating object to capturing frame from inbult camera(0) or the external camera(1)\n",
    "cap = cv2.VideoCapture(gstreamer_pipeline(flip_method=0), cv2.CAP_GSTREAMER)\n",
    "\n",
    "if testmode == 1:\n",
    "    display_handle=display(None, display_id=True)\n",
    "    navigation_w = ipywidgets.Image(format='jpeg')\n",
    "\n",
    "StepSize = 5\n",
    "\n",
    "try:\n",
    "    while (1):\n",
    "        _, frame = cap.read()  # Reading the frame from the object.\n",
    "\n",
    "        original_frame = frame.copy()  # Copy of frame which will be used for to compare with other images after appling various operations.\n",
    "        img_edgerep = frame.copy()  # Copy of frame which will be used for edge representation.\n",
    "        img_contour = frame.copy()  # Copy of frame which will be used for drawing contours.\n",
    "        img_navigation = frame.copy()  # Copy of frame which will be used for indicating direction of navigation.\n",
    "\n",
    "        blur = cv2.bilateralFilter(img_edgerep, 9, 40, 40)  # Blurring the image to remove the noise present in the image.\n",
    "        edges = cv2.Canny(blur, 50, 100)  # Obtaining clear edges using canny edge detector.\n",
    "\n",
    "        img_edgerep_h = img_edgerep.shape[0] - 1  # Storing the height of the image which will be used in for loop.\n",
    "        img_edgerep_w = img_edgerep.shape[1] - 1  # Storing the width of the image which will be used in for loop.\n",
    "\n",
    "        EdgeArray = []  # Initilizing the array to store the concerned edges for edge representation.\n",
    "\n",
    "        for j in range(0, img_edgerep_w, StepSize):  # FOR loop along the width of the image with given stepsize.\n",
    "            pixel = (j, 0)  # If no edge found in column this value will be stored in edgearray.\n",
    "            for i in range(img_edgerep_h - 5, 0, -1):  # FOR loop along the height of the image.\n",
    "                if edges.item(i, j) == 255:  # Checking for edges.\n",
    "                    pixel = (j, i)\n",
    "                    break  # If edge is found break and go for the next colomn.\n",
    "            EdgeArray.append(pixel)  # Store the eged detected in EgdeArray.\n",
    "\n",
    "        for x in range(len(\n",
    "                EdgeArray) - 1):  # Joining each edge to diferentiate the frame into free space and conjusted space(with objects)\n",
    "            cv2.line(img_edgerep, EdgeArray[x], EdgeArray[x + 1], (0, 255, 0), 1)\n",
    "\n",
    "        for x in range(len(\n",
    "                EdgeArray)):  # Joining each point in the EdgeArray to the respective bottom edge of the frame to represent free space for the bot to move around\n",
    "            cv2.line(img_edgerep, (x * StepSize, img_edgerep_h), EdgeArray[x], (0, 255, 0), 1)\n",
    "\n",
    "        # Code to draw contours.\n",
    "\n",
    "        blurred_frame = cv2.bilateralFilter(img_contour, 9, 75, 75)\n",
    "        gray = cv2.cvtColor(blurred_frame, cv2.COLOR_BGR2GRAY)\n",
    "        ret, thresh = cv2.threshold(gray, 106, 255, 1)\n",
    "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(img_edgerep, contours, -1, (0, 0, 255), 3)\n",
    "\n",
    "        # Code to decide direction of navigation\n",
    "\n",
    "        number_of_chunks = 3\n",
    "        size_of_chunk = int(len(EdgeArray) / number_of_chunks)\n",
    "        chunks = make_chunks(EdgeArray, size_of_chunk)  # Calling make_chunks function to create the chunks.\n",
    "        avg_of_chunk = []\n",
    "        for i in range(len(chunks) - 1):\n",
    "            x_vals = []\n",
    "            y_vals = []\n",
    "            for (x, y) in chunks[i]:  # Storing the x and y value saperatly to find average.\n",
    "                x_vals.append(x)\n",
    "                y_vals.append(y)\n",
    "            avg_x = int(np.average(x_vals))\n",
    "            avg_y = int(np.average(y_vals))\n",
    "            avg_of_chunk.append([avg_y, avg_x])\n",
    "            cv2.line(frame, (int(img_edgerep_w / 2), img_edgerep_h), (avg_x, avg_y), (255, 0, 0),\n",
    "                         2)  # Draw lines to each average chunks to decide the direction of navigation.\n",
    "\n",
    "        forwardEdge = avg_of_chunk[1]\n",
    "        cv2.line(frame, (int(img_edgerep_w / 2), img_edgerep_h), (forwardEdge[1], forwardEdge[0]), (0, 255, 0), 3)\n",
    "        farthest_point = (min(avg_of_chunk))\n",
    "        # print(farthest_point)\n",
    "\n",
    "        if forwardEdge[0] > 250:  # Checking for the object at the front is close to bot.\n",
    "            if farthest_point[1] < 310:  # Checking for the farthest_point on the left of the frame.\n",
    "                direction = \"Move left \"\n",
    "                print(direction)\n",
    "            else:\n",
    "                direction = \"Move right \"\n",
    "                print(direction)\n",
    "        else:\n",
    "            direction = \"Move forward \"\n",
    "            print(direction)\n",
    "\n",
    "            # Code to display the results\n",
    "        if testmode == 1:\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            navigation = cv2.putText(frame, direction, (275, 50), font, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            clear_output(wait=True)            \n",
    "            lines, columns, _ =  navigation.shape\n",
    "            navigation = cv2.resize(navigation, (int(columns/4), int(lines/4)))\n",
    "            navigation_w.value =cv2.imencode('.jpeg', navigation)[1].tobytes()\n",
    "            display(navigation_w)\n",
    "            \n",
    "            time.sleep(0.025)\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    cap.release()\n",
    "    display_handle.update(None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navigation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
